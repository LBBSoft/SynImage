# -*- coding: utf-8 -*-
"""Cell line_Features.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PlgXE_O93AXUl-y3j1a3Tt3y6fhCCjsO
"""

#install packeges
pip install scikit-learn==1.1.0
pip install pyDeepInsight
pip install umap-learn
pip install grad-cam
pip install torchcam
pip install torch==1.13.*

# import some packages
from matplotlib import pyplot as plt
import matplotlib.ticker as ticker
from PIL import Image
import pandas as pd
import numpy as np
import inspect
from IPython.display import display, clear_output
from sklearn.manifold import TSNE
from sklearn.cluster import BisectingKMeans
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from scipy.spatial import ConvexHull
from scipy.spatial.distance import cdist
import timm
import pyDeepInsight
from pyDeepInsight import ImageTransformer
from pyDeepInsight.utils import Norm2Scaler
import umap.umap_ as umap
import torch
import torchvision.transforms as transforms
from torch.utils.data import TensorDataset, DataLoader
import torch.nn as nn
import torch.optim as optim
from torchvision.io import read_image
from torchvision.models import resnet18, ResNet18_Weights
from torchvision.models.feature_extraction import create_feature_extractor

# Load the cell gene expression data from a CSV file
cells = pd.read_csv('path/Data/cell_gEXP_ONEIL_LINCS.csv')

# Extract the 'name' column from the 'cells' DataFrame as the target variable
y = cells['name'].values

# Extract all columns except the first one from the 'cells' DataFrame as features
X = cells.iloc[:, 1:].values

# Filter features based on variance threshold
var_filter = X.var(axis=0) >= np.percentile(X.var(axis=0), 30., method='nearest')

# Initialize a MinMaxScaler
mms = MinMaxScaler()

# Normalize the data using MinMaxScaler, applying only to columns that pass the variance filter
X_norm = mms.fit_transform(X[:, var_filter])

# Check for infinite values in the normalized data
if np.isinf(X_norm).any():
    print("There are Inf or -Inf values in X_norm")

# Check for NaN values in the normalized data
if np.isnan(X_norm).any():
    print("There are NaN values in X_norm")

#Reduces image features using UMAP and transforms images to 224x224 pixels
reducer = umap.UMAP(
    n_components=2,
    min_dist=0.8,
    metric='cosine',
    n_jobs=-1
)

pixel_size = (224,224)
it = ImageTransformer(
    feature_extractor=reducer,
    pixels=pixel_size)

# Fit the ImageTransformer model to the normalized data and plot the results
it.fit(X_norm, y, plot=True)

# Transform the normalized data using the fitted ImageTransformer
X_img = it.transform(X_norm)

# Step 1: Initialize model with the best available weights
weights = ResNet18_Weights.DEFAULT
model = resnet18(weights=weights)
model.eval()

# Step 2: Initialize the inference transforms
preprocess = weights.transforms()

# Step 3: Create the feature extractor with required nodes
return_nodes = {'flatten': 'flatten'}
feature_extractor = create_feature_extractor(model, return_nodes=return_nodes)

# Define a preprocessing transformation (example for ImageNet statistics)
preprocess = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Assuming X_img is a NumPy array with shape (34, 224, 224, 3)
# Initialize a list to store the feature tensors
feature_tensors = []

# Iterate over each image in X_img
for img in X_img:
    # Convert the image to a PyTorch tensor and apply preprocessing
    image_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension

    # Convert the image tensor to Float if it's not already
    if image_tensor.dtype == torch.float64:
        image_tensor = image_tensor.float()

    # Now image_tensor should be of type Float (torch.float32)
    features = feature_extractor(image_tensor)

    # If you need to flatten the features, you can do so
    flatten_fts = features["flatten"].squeeze()

    # Append the flattened features to the list
    feature_tensors.append(flatten_fts)

# Convert the list of feature tensors to a single stacked tensor
features_stack = torch.stack(feature_tensors)

Resnet18_cell_features=pd.DataFrame(features_stack.detach().numpy())
Resnet18_cell_features.insert(0, 'name', cells['name'])

# Save the ResNet18 cell features to a CSV file without including the index
Resnet18_cell_features.to_csv(f'path/Data/Resnet18_cell_features.csv', index=False)